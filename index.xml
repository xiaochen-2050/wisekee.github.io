<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Xiao.chen</title>
    <link>https://blog.wisekee.com/</link>
    <description>Recent content on Xiao.chen</description>
    <generator>Hugo -- gohugo.io</generator>
    <copyright>Copyright © 2008–2020, Xiao.chen; all rights reserved.</copyright>
    <lastBuildDate>Fri, 15 Jan 2021 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="https://blog.wisekee.com/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Installing eclipse-che in native kubernetes platform</title>
      <link>https://blog.wisekee.com/post/installing-eclipse-che-in-kubernetes/</link>
      <pubDate>Fri, 15 Jan 2021 00:00:00 +0000</pubDate>
      
      <guid>https://blog.wisekee.com/post/installing-eclipse-che-in-kubernetes/</guid>
      <description>At first installing OLM Requirement: kubectl configred and connect to Kubernetes cluster correct.
1curl -L https://github.com/operator-framework/operator-lifecycle-manager/releases/download/v0.17.0/install.sh -o install.sh 2chmod +x install.sh 3./install.sh v0.17.0 Installing Eclipse-Che Operator According to: eclipse-che operator
1kubectl create -f https://operatorhub.io/install/eclipse-che.yaml 2# view the Operator resources 3kubectl get pods --all-namespaces | grep olm 4# and the CluseterServiceVersion 5kubectl get csv -n my-eclipse-che Install Eclipse-che instance use CheCluster resource 1#The partial configure need to change2k8s:3ingressClass:&amp;#39;nginx&amp;#39;4ingressDomain:&amp;#39;che.dev.com&amp;#39;5ingressStrategy:&amp;#39;single-host&amp;#39;6securityContextFsGroup:&amp;#39;&amp;#39;7securityContextRunAsUser:&amp;#39;&amp;#39;8singleHostExposureType:&amp;#39;&amp;#39;9tlsSecretName:&amp;#39;self-domain-cert&amp;#39;10server:11cheHost:&amp;#39;che.dev.com&amp;#39;12cheHostTLSSecret:&amp;#39;self-domain-cert&amp;#39;13#You can add more custom properties refer to this url: https://www.</description>
    </item>
    
    <item>
      <title>Kubernetes events collect to elasticsearch</title>
      <link>https://blog.wisekee.com/post/kubernetes-events-to-es/</link>
      <pubDate>Wed, 16 Dec 2020 00:00:00 +0000</pubDate>
      
      <guid>https://blog.wisekee.com/post/kubernetes-events-to-es/</guid>
      <description>We what collect and storage kubernetes events to elasticsearch, easy to query and analyze alerts. we use this github repo componentkubernetes-event-exporter
The main.tf include kubernetes &amp;lsquo;deployment&amp;rsquo; object 1resource&amp;#34;kubernetes_deployment&amp;#34;&amp;#34;event_export&amp;#34;{2metadata{3name=&amp;#34;event-export&amp;#34;4namespace=&amp;#34;kube-system&amp;#34;5labels={6app=&amp;#34;event-export&amp;#34;7}8}910spec{11replicas=11213selector{14match_labels={15app=&amp;#34;event-export&amp;#34;16}17}1819template{20metadata{21labels={22app=&amp;#34;event-export&amp;#34;23version=&amp;#34;v1&amp;#34;24}25}2627spec{28service_account_name=kubernetes_service_account.event_export.metadata[0].name29automount_service_account_token=true30container{31image=&amp;#34;opsgenie/kubernetes-event-exporter:0.9&amp;#34;32args=[33&amp;#34;-conf=/data/config.yaml&amp;#34;,34]35name=&amp;#34;event-export&amp;#34;36resources{37requests{38memory=&amp;#34;50Mi&amp;#34;39}40limits{41memory=&amp;#34;100Mi&amp;#34;42}43}44volume_mount{45name=&amp;#34;cfg&amp;#34;46mount_path=&amp;#34;/data&amp;#34;47}48image_pull_policy=&amp;#34;IfNotPresent&amp;#34;49}50volume{51name=&amp;#34;cfg&amp;#34;52config_map{53name=kubernetes_config_map.event_export_config.metadata[0].name54}55}56}57}58}5960depends_on=[61kubernetes_service_account.event_export62]6364}The configmap.tf indlude the kubernetes configMap object storage event-exporter&amp;rsquo;s config as volume mount to previous deployment&amp;rsquo;s pod container 1resource&amp;#34;kubernetes_config_map&amp;#34;&amp;#34;event_export_config&amp;#34;{2metadata{3name=&amp;#34;event-export-config&amp;#34;4namespace=&amp;#34;kube-system&amp;#34;5}6data={7&amp;#34;config.yaml&amp;#34;=&amp;lt;&amp;lt;-EOF8logLevel:error9logFormat:json10route:11routes:12- match:13- type:&amp;#34;Warning&amp;#34;14receiver:&amp;#34;dump&amp;#34;15- match:16- type:&amp;#34;Error&amp;#34;17receiver:&amp;#34;dump&amp;#34;18receivers:19- name:&amp;#34;dump&amp;#34;20file:21path:&amp;#34;dev/stderr&amp;#34;22EOF23}2425}In this config section, we decides collect the Error and Warning events only. And this component support for AWS ElasticSearch is not good, we output events directly to the Console, after which the ES are collected through Fluentdfluentd service</description>
    </item>
    
    <item>
      <title>Terraform&#43;Helm release&#43;fluentd in kubernetes</title>
      <link>https://blog.wisekee.com/post/terraform-helm-fluentd/</link>
      <pubDate>Wed, 02 Dec 2020 00:00:00 +0000</pubDate>
      
      <guid>https://blog.wisekee.com/post/terraform-helm-fluentd/</guid>
      <description>step1 the main.tf include following contents: 1resource&amp;#34;helm_release&amp;#34;&amp;#34;fluentd_server&amp;#34;{2name=&amp;#34;fluentd-server&amp;#34;3repository=&amp;#34;https://charts.bitnami.com/bitnami&amp;#34;4# chart = &amp;#34;${path.module}/../../../../../charts/fluentd&amp;#34;5version=&amp;#34;3.1.0&amp;#34;6namespace=&amp;#34;kube-system&amp;#34;78values=[9&amp;lt;&amp;lt;-EOF10forwarder:11configMap:&amp;#34;fluentd-forwarder-config&amp;#34;12rbac:13pspEnabled:true14resources:15limits:16memory:1Gi17requests:18memory:512Mi19aggregator:20replicaCount:121configMap:&amp;#34;fluentd-elasticsearch-config&amp;#34;22resources:23limits:24memory:1Gi25requests:26memory:512Mi27extraEnv:28- name:ELASTICSEARCH_HOST29value:&amp;#34;${var.es_url}&amp;#34;30- name:ELASTICSEARCH_PORT31value:&amp;#34;80&amp;#34;32- name:ELASTICSEARCH_SCHEME33value:&amp;#34;http&amp;#34;34persistence:35enabled:true36storageClass:gp237EOF38]3940depends_on=[41kubernetes_config_map.fluentd_elasticsearch_output,42kubernetes_config_map.fluentd_forwarder_config43]4445}step2 the fluentd aggegator configmap config aggregator_configmap.tf 1resource&amp;#34;kubernetes_config_map&amp;#34;&amp;#34;fluentd_elasticsearch_output&amp;#34;{2metadata{3name=&amp;#34;fluentd-elasticsearch-config&amp;#34;4namespace=&amp;#34;kube-system&amp;#34;5}6data={7&amp;#34;fluentd.conf&amp;#34;=&amp;lt;&amp;lt;-EOF8# Prometheus Exporter Plugin9# input plugin that exports metrics10&amp;lt;source&amp;gt; 11@type prometheus12port2423113&amp;lt;/source&amp;gt; 1415# input plugin that collects metrics from MonitorAgent16&amp;lt;source&amp;gt; 17@type prometheus_monitor18&amp;lt;labels&amp;gt; 19host $${hostname}20&amp;lt;/labels&amp;gt; 21&amp;lt;/source&amp;gt;2223# input plugin that collects metrics for output plugin24&amp;lt;source&amp;gt; 25@type prometheus_output_monitor26&amp;lt;labels&amp;gt; 27host $${hostname}28&amp;lt;/labels&amp;gt; 29&amp;lt;/source&amp;gt;3031# Ignore fluentd own events32&amp;lt;matchfluent.**&amp;gt;33@typenull34&amp;lt;/match&amp;gt; 3536# TCP input to receive logs from the forwarders37&amp;lt;source&amp;gt; 38@type forward39bind0.</description>
    </item>
    
    <item>
      <title>Getting started Serverless framework Nuclio</title>
      <link>https://blog.wisekee.com/post/getting-stared-nucalio/</link>
      <pubDate>Sun, 15 Nov 2020 00:00:00 +0000</pubDate>
      
      <guid>https://blog.wisekee.com/post/getting-stared-nucalio/</guid>
      <description>use Helm charts: Github  1	helm repo add nuclio https://nuclio.github.io/nuclio/charts 2	kubectl create namespace nuclio  copy registry to nuclio namespace from existing namespace  1kubectl get secret repo-registry -n dev-ns -o yaml \ 2| sed s/&amp;#34;namespace: dev-ns&amp;#34;/&amp;#34;namespace: nuclio&amp;#34;/ \ 3| kubectl apply -f -  install nuclio  1	helm install nuclio \ 2 --set registry.secretName=repo-registry \ 3 --set registry.pushPullUrl=localhost/nucalio \ 4 nuclio/nuclio -n nuclio  visit dashboard  1	kubectl -n nuclio port-forward $(kubectl get pods -n nuclio -l nuclio.</description>
    </item>
    
    <item>
      <title>Scheduler clean up kubernetes unuseful resources</title>
      <link>https://blog.wisekee.com/post/schedule-cleanup-k8s-resources/</link>
      <pubDate>Mon, 02 Nov 2020 00:00:00 +0000</pubDate>
      
      <guid>https://blog.wisekee.com/post/schedule-cleanup-k8s-resources/</guid>
      <description>Prepare Golang program code use clean up unused pods and replicaset resources in kubernetes we can clean up not running status pods and deactive replicasets
 initialization Go lanugage project evnironment  1	mkdir k8s_res_cleanup &amp;amp;&amp;amp; cd k8s_res_cleanup 2	go mod init example.com/cleanup/resources 3	go get -v -u k8s.io/client-go@v0.18.2 # install packages 4	go get -v -u github.com/prometheus/common@v0.1.0  create sub packageconfig/k8s.go indicate how can connect to kubernetes cluster  1package config 2 3import ( 4	&amp;#34;flag&amp;#34; 5	logs &amp;#34;github.</description>
    </item>
    
    <item>
      <title>Solve the problem of Metrics - Server</title>
      <link>https://blog.wisekee.com/post/k8s-metrics-server/</link>
      <pubDate>Sun, 25 Oct 2020 00:00:00 +0000</pubDate>
      
      <guid>https://blog.wisekee.com/post/k8s-metrics-server/</guid>
      <description>When we repeatedly install the Metrics-Server, because we use helm to install it, deleting one of them will cause the following error when executing the command related to kubectl top nodes:  Error from server (NotFound): the server could not find the requested resource (get services http:heapster:)
  A large part of this is due to the removal of the Apiservice Resources from Metics, when you execute the following command to ensure that the Apiservice exists  kubectl get apiservice | grep metrics   v1beta1.</description>
    </item>
    
    <item>
      <title>Notes for using Kubernetes Ingress Controller</title>
      <link>https://blog.wisekee.com/post/kubernetes-ingress-guides/</link>
      <pubDate>Thu, 15 Oct 2020 00:00:00 +0000</pubDate>
      
      <guid>https://blog.wisekee.com/post/kubernetes-ingress-guides/</guid>
      <description>Using Nginx-Ingress Controller in AWS Eks environment  Need manually enable the Proxy protocol V2 in NLB target group just only TCP https 443 listener Rather than TCP http 80 listener Multiple SSL certificate need manually add to NLB The http redirect to https, need to change some paramets  1# use http-snippet and open proxy protocol2use-proxy-protocol:&amp;#39;true&amp;#39;3use-forwarded-headers:&amp;#39;true&amp;#39;4server-tokens:&amp;#39;false&amp;#39;5http-snippet:| 6server {7listen8000;8return308https://$host$request_uri;9}10proxy-real-ip-cidr:${join(&amp;#34;,&amp;#34;,var.internal_cidr)}11# Add special port in controller container12set{13type=&amp;#34;string&amp;#34;14name=&amp;#34;controller.containerPort.special&amp;#34;15value=&amp;#34;8000&amp;#34;16}17# Let https redirect to http port and http port redirect to special port , the special port listener in `http-snippet` section18set{19type=&amp;#34;string&amp;#34;20name=&amp;#34;controller.</description>
    </item>
    
    <item>
      <title>Airflow console logs display in kuberntes container executor</title>
      <link>https://blog.wisekee.com/post/airflow-kuberntes-logs-config/</link>
      <pubDate>Sun, 11 Oct 2020 00:00:00 +0000</pubDate>
      
      <guid>https://blog.wisekee.com/post/airflow-kuberntes-logs-config/</guid>
      <description>Problem description When use kubernetes executor in airflow, the dags not use the podOperator but that use PythonOperator, the console logs end of Running %s on host %s &amp;lt;TaskInstance:, then the task logs don&amp;rsquo;t redirect to stdout According to the Airflow descript need config the logging class: custom_log_settings 
Change the custom log settings comment relative code and enable to console the tee_file_task_handler.py edit the following code snippet.
 comment the following content.</description>
    </item>
    
    <item>
      <title>Points to note about  Terraform helm provider</title>
      <link>https://blog.wisekee.com/post/terraform-helm-issues/</link>
      <pubDate>Sat, 10 Oct 2020 00:00:00 +0000</pubDate>
      
      <guid>https://blog.wisekee.com/post/terraform-helm-issues/</guid>
      <description>The Metrics-Server helm chart as Terraform HCL 1resource&amp;#34;helm_release&amp;#34;&amp;#34;metrics-server&amp;#34;{2name=&amp;#34;metrics-server&amp;#34;3repository=&amp;#34;https://charts.bitnami.com/bitnami&amp;#34;4chart=&amp;#34;metrics-server&amp;#34;5version=&amp;#34;4.1.4&amp;#34;6namespace=&amp;#34;kube-system&amp;#34;78set{9name=&amp;#34;extraArgs.kubelet-preferred-address-types&amp;#34;10value=&amp;#34;InternalIP\\,ExternalIP\\,Hostname&amp;#34;11}1213set{14name=&amp;#34;resources.requests.memory&amp;#34;15value=&amp;#34;500Mi&amp;#34;16}1718set{19name=&amp;#34;resources.limits.memory&amp;#34;20value=&amp;#34;1Gi&amp;#34;21}2223set{24name=&amp;#34;apiService.create&amp;#34;25value=&amp;#34;true&amp;#34;26}2728} The apiService.create always assign to true when in AWS EKS or other kubernetes distribution The values include comma , muste be use escape in terraform Any resources should be specific quota, like resource requests and limits  When Name includes dot annotations also escaped 1# set {2# type = &amp;#34;string&amp;#34;3# name = &amp;#34;ingress.web.annotations.alb\\.ingress\\.kubernetes\\.io/security-groups&amp;#34;4# value = &amp;#34;${var.office_sg_id}\\,${var.internal_sg_id}\\,${var.cluster_sg_id}&amp;#34;5# }terraform helm release use local charts 1resource&amp;#34;helm_release&amp;#34;&amp;#34;fluentd_server&amp;#34;{2name=&amp;#34;fluentd-server&amp;#34;3# repository = &amp;#34;https://charts.</description>
    </item>
    
    <item>
      <title>Backup and Restore kubernetes cluster using Velero</title>
      <link>https://blog.wisekee.com/post/k8s-backup-restore-using-velero/</link>
      <pubDate>Thu, 10 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>https://blog.wisekee.com/post/k8s-backup-restore-using-velero/</guid>
      <description>Installing or Upgrade Velero client on Mac OS:
1	brew install velero 2	HOMEBREW_NO_AUTO_UPDATE=1 brew upgrade velero #upgrade to the latest version if maybe The Velero should use object store save the snapshot. so we use Minio as kubernetes object store.Minio launched as part of docker-compose.yaml
1minio:2container_name:&amp;#34;minio&amp;#34;3image:minio/minio4command:&amp;#34;server /data&amp;#34;5ports:6- &amp;#34;9000:9000&amp;#34;7environment:8MINIO_ACCESS_KEY:“xxxxxxx”9MINIO_SECRET_KEY:“xxxxxxx”10volumes:11- &amp;#34;./minio/data:/data&amp;#34;12networks:13- easy-mockCreate a env file is named: velero-env. because the Velero need the similar aws credentials access to Minio service storage backup object.</description>
    </item>
    
    <item>
      <title>Custom private domain name in kubernetes cluster</title>
      <link>https://blog.wisekee.com/post/custom-domain-name-in-k8s/</link>
      <pubDate>Thu, 03 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>https://blog.wisekee.com/post/custom-domain-name-in-k8s/</guid>
      <description>We use default service domain name ${servicename}.${namespace}.svc.cluster.localin kubernetes cluster, however the custom private domain name in private k8s networks frequently used. we can use coredns component reparse the private domain name to default CNAME.
change coredns configmap add custom domain name config to yaml kubectl edit cm coredns -n kube-system
1data:2Corefile:| 3.:53 {4errors5health{6lameduck5s7}8ready9kubernetescluster.localin-addr.arpaip6.arpa{10podsinsecure11fallthroughin-addr.arpaip6.arpa12ttl3013}14file/etc/coredns/uat-env.dbuat-env.com15prometheus:915316forward./etc/resolv.conf17cache3018loop19reload20loadbalance21}22uat-env.db:&amp;gt;- 23uat-env.com. IN SOA ns.dns.cluster.local. 24hostmaster.cluster.local.15923622027200180086400302526uat-env.com.INNS27kube-dns.kube-system.svc.cluster.local.2829db.uat-env.com.INCNAME30mysql.db.svc.cluster.local.3132private-services.uat-env.com.INCNAME33internal-gateway.default.svc.cluster.local.add file /etc/coredns/uat-env.db uat-env.com line to Corefile section add new section uat-env.db and add relative recordset</description>
    </item>
    
    <item>
      <title>Quickly debug AWS App locally use Localstack(AWS Mock in local)</title>
      <link>https://blog.wisekee.com/post/aws-local-development/</link>
      <pubDate>Tue, 01 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>https://blog.wisekee.com/post/aws-local-development/</guid>
      <description>When you develop components locally that rely on AWS, it can be cumbersome to configure authentication information, and sometimes network latency. It is important to mock with a native AWS component, which can:localstack I&amp;rsquo;m using Docker-Compose here to start a set of tools that local development depends on：
The docker-compose.yml looks like this following 1version:&amp;#39;3&amp;#39;23services:4mongodb:5image:mongo:3.4.16volumes:7- &amp;#39;./easymock/data/db:/data/db&amp;#39;8networks:9- easy-mock10ports:11- &amp;#34;27017:27017&amp;#34;12restart:always13container_name:mongodb1415redis:16image:redis:4.0.617command:redis-server--appendonlyyes18volumes:19- &amp;#39;./easymock/data/redis:/data&amp;#39;20networks:21- easy-mock22restart:always23container_name:redis2425localstack:26container_name:&amp;#34;${LOCALSTACK_DOCKER_NAME-localstack}&amp;#34;27image:localstack/localstack28ports:29- &amp;#34;4567-4597:4567-4597&amp;#34;30environment:31- DEBUG=${DEBUG-true}32- DATA_DIR=${DATA_DIR-/tmp/localstack/data}33- PORT_WEB_UI=${PORT_WEB_UI-8080}34- LAMBDA_EXECUTOR=${LAMBDA_EXECUTOR-docker-reuse}35- DOCKER_HOST=unix:///var/run/docker.sock36- HOSTNAME_EXTERNAL=awsmock.local-dev.com37volumes:38- &amp;#34;./localstack/data:/tmp/localstack&amp;#34;39- &amp;#34;/var/run/docker.sock:/var/run/docker.sock&amp;#34;40networks:41- easy-mock4243mysql:44container_name:&amp;#34;mysql&amp;#34;45image:mysql46command:&amp;#34;--default-authentication-plugin=mysql_native_password --skip-mysqlx&amp;#34;47ports:48- &amp;#34;3306:3306&amp;#34;49environment:50MYSQL_ROOT_PASSWORD:&amp;#34;xxxxx&amp;#34;51MYSQL_DATABASE:&amp;#34;awsmock&amp;#34;52MYSQL_PASSWORD:&amp;#34;xxxxx&amp;#34;53MYSQL_USER:&amp;#34;user&amp;#34;54volumes:55- &amp;#34;.</description>
    </item>
    
    <item>
      <title>kubernetes operations command summary</title>
      <link>https://blog.wisekee.com/post/k8s-common-command-conclusion/</link>
      <pubDate>Tue, 25 Aug 2020 00:00:00 +0000</pubDate>
      
      <guid>https://blog.wisekee.com/post/k8s-common-command-conclusion/</guid>
      <description>When we use the Kubernetes platform,has many commands is important:
 The k command is alias to kubectl
   label for nodes kubectl label nodes host02 disktype=ssd
  view local config for kubernetes context k config get-contexts
  switch context&amp;rsquo;s namespaces kubectl config set-context my-vsphere-cluster --namespace=helm-test
  force delete pod, sometimes the pod still terminating.
k delete pods &amp;lt;pod&amp;gt; -n &amp;lt;namespace&amp;gt; --grace-period=0 --force
  get all resource in current kubernetes cluster</description>
    </item>
    
    <item>
      <title>Php file cache in project</title>
      <link>https://blog.wisekee.com/post/laravel-librarys/</link>
      <pubDate>Tue, 25 Aug 2020 00:00:00 +0000</pubDate>
      
      <guid>https://blog.wisekee.com/post/laravel-librarys/</guid>
      <description>use cache library out of laravel framework 1&amp;lt;?php 2 3namespace Company; 4 5 6use Illuminate\Cache\CacheManager; 7use Illuminate\Container\Container; 8use Illuminate\Filesystem\Filesystem; 9 10class FileCache { 11 12 13 private $cacheManager; 14 private $cache; 15 16 private function __construct() 17 { 18 $container = new Container(); 19 $container[&amp;#39;config&amp;#39;] = [ 20 &amp;#39;cache.default&amp;#39; =&amp;gt; &amp;#39;file&amp;#39;, 21 &amp;#39;cache.stores.file&amp;#39; =&amp;gt; [ 22 &amp;#39;driver&amp;#39; =&amp;gt; &amp;#39;file&amp;#39;, 23 &amp;#39;path&amp;#39; =&amp;gt; __DIR__ . &amp;#39;/../../../storage/framework/cache&amp;#39; 24 ] 25 ]; 26 27 $container[&amp;#39;files&amp;#39;] = new Filesystem(); 28 $this-&amp;gt;cacheManager = new CacheManager($container); 29 $this-&amp;gt;cache = $this-&amp;gt;cacheManager-&amp;gt;store(); 30 } 31 32 public static function rememberForever($key, callable $callBack) { 33 return (new static()) 34 -&amp;gt;cache 35 -&amp;gt;rememberForever($key, $callBack); 36 } 37} use file cache get AWS SecretsManager item 1&amp;lt;?</description>
    </item>
    
    <item>
      <title>Automatic generate kubernetes custom resources api go language code</title>
      <link>https://blog.wisekee.com/post/generate-crds-api-k8s/</link>
      <pubDate>Sat, 22 Aug 2020 00:00:00 +0000</pubDate>
      
      <guid>https://blog.wisekee.com/post/generate-crds-api-k8s/</guid>
      <description>Why does this article exist because when we use Kubesphere. the go client code need to use the client objects of K8s but dosen&amp;rsquo;t provider the s2ibinary object client code. https://github.com/kubesphere/s2ioperator/tree/master/pkg/client/clientset/versioned/typed/devops/v1alpha1
  Prepare directory structure and resource defination files    The doc.go include content:  1// +k8s:deepcopy-gen=package,register 2// +k8s:defaulter-gen=TypeMeta 3// +groupName=devops.kubesphere.io 4package v1alpha1  The register.go main defination custom resources GroupName and GroupVersion  1package v1alpha1 2 3import ( 4 &amp;#34;k8s.</description>
    </item>
    
    <item>
      <title>Install and setup cloud foundry in kubernetes cluster</title>
      <link>https://blog.wisekee.com/post/setup-cloudfoundry-in-k8s/</link>
      <pubDate>Thu, 20 Aug 2020 00:00:00 +0000</pubDate>
      
      <guid>https://blog.wisekee.com/post/setup-cloudfoundry-in-k8s/</guid>
      <description>First prepare the tools installation in host:  Kind: https://kind.sigs.k8s.io/docs/user/quick-start/ Cf command: https://docs.cloudfoundry.org/cf-cli/install-go-cli.html  HOMEBREW_NO_AUTO_UPDATE=1 brew install cloudfoundry/tap/cf-cli@6 or HOMEBREW_NO_AUTO_UPDATE=1 brew install cloudfoundry/tap/cf-cli@7   Kubectl command: https://kubernetes.io/docs/tasks/tools/install-kubectl/ Helm: https://helm.sh/docs/intro/install/  The Kind must definiation config.yml, refer to expose http(80) and https(443) ports to host machine, because the k8s cluster node ip is internal-ip created by Kind such as: 172.18.0.2
1kind:Cluster2apiVersion:kind.x-k8s.io/v1alpha43networking:4# WARNING: It is _strongly_ recommended that you keep this the default5# (127.</description>
    </item>
    
    <item>
      <title>Laravel ip allowlist request filter middleware</title>
      <link>https://blog.wisekee.com/post/laravel-php-snippets/</link>
      <pubDate>Sat, 15 Aug 2020 00:00:00 +0000</pubDate>
      
      <guid>https://blog.wisekee.com/post/laravel-php-snippets/</guid>
      <description>Temporary ip allow list in PHP framework Laravel 1&amp;lt;?php 2 3namespace App\Http\Middleware; 4 5use Closure; 6use Illuminate\Http\Request; 7use Illuminate\Support\Facades\Cache; 8use Illuminate\Support\Facades\Log; 9use Symfony\Component\HttpFoundation\IpUtils; 10 11class IpAllowMiddleware 12{ 13 /** 14* Handle an incoming request. 15* 16* @param \Illuminate\Http\Request $request 17* @param \Closure $next 18* @return mixed 19*/ 20 public function handle($request, Closure $next) 21 { 22 $this-&amp;gt;setTrustProxy(); 23 $clientIp = $request-&amp;gt;getClientIp(); 24 if (!$this-&amp;gt;compareOrigin($clientIp)) { 25 Log::warning(&amp;#34;The client ip is forbidden: &amp;#34; .</description>
    </item>
    
    <item>
      <title>Go language frequently used command notes</title>
      <link>https://blog.wisekee.com/post/go-usually-commands/</link>
      <pubDate>Wed, 11 Sep 2019 00:00:00 +0000</pubDate>
      
      <guid>https://blog.wisekee.com/post/go-usually-commands/</guid>
      <description>Global install go program(go version &amp;gt;=1.16.0)  go install sigs.k8s.io/kind@v0.9.0  when go version is higher 1.12 should install godoc command  go get golang.org/x/tools/cmd/godoc  launch go docs services in local  godoc -http=:6060  view go environment variables,inlude GO ROOT path  go env  fmt package Println docs  go doc fmt Println  initialization go modules, when reference sub directory straightway example.com/module/sub1/sub2  go mod init example.</description>
    </item>
    
    <item>
      <title>ElasticSearch monitoring and  alert base on ElastAlert</title>
      <link>https://blog.wisekee.com/post/elastalert-usage/</link>
      <pubDate>Tue, 02 Jul 2019 00:00:00 +0000</pubDate>
      
      <guid>https://blog.wisekee.com/post/elastalert-usage/</guid>
      <description>Dynamically generate alarm rules and send email to relative people.based on a given parameter or configuration Elastalert
The directory construct look following 1├── elastalert 2├── generate_rule.py 3├── param.json 4├── rules 5└── template You can also through pip install elastalert installing elastalert package. I&amp;rsquo;m going to use it directly here The templatedirectory store tpl file, use this template generate some rules file to rules directory. and used elastalert
Configuration file param.json 1{ 2 &amp;#34;dev&amp;#34;: { 3 &amp;#34;public_config&amp;#34;: { 4 &amp;#34;run_every&amp;#34;: 5, 5 &amp;#34;buffer_time&amp;#34;: 15, 6 &amp;#34;es_host&amp;#34;: &amp;#34;dev.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://blog.wisekee.com/archives/</link>
      <pubDate>Tue, 28 May 2019 00:00:00 +0000</pubDate>
      
      <guid>https://blog.wisekee.com/archives/</guid>
      <description></description>
    </item>
    
    <item>
      <title>AWS networking security enhance</title>
      <link>https://blog.wisekee.com/post/aws-network-secrutiy-enhance/</link>
      <pubDate>Sun, 05 May 2019 00:00:00 +0000</pubDate>
      
      <guid>https://blog.wisekee.com/post/aws-network-secrutiy-enhance/</guid>
      <description>Vpc network division According to the requirements of the product and the customer, the two services of the two types of subnets are isolated. For example, DBsubnet01 and DBsubnet02 are both internal private subnets and belong to different product segments. ​	 The two major subnet types are the intranet and the extranet. The internal network goes to the NAT Gateway, and the external network goes to the Internet Gateway. Like: RDS, Redis, background services, etc.</description>
    </item>
    
    <item>
      <title>About</title>
      <link>https://blog.wisekee.com/about/</link>
      <pubDate>Thu, 28 Feb 2019 00:00:00 +0000</pubDate>
      
      <guid>https://blog.wisekee.com/about/</guid>
      <description>I have 13 years of working experience in the IT industry in China from Qbasic language in high school to Foxbase,PowerBuilder and other traditional C/S software development tool sets. With the vigorous development of Internet, ASP language has been used to make dynamic website since 2002. Later, I turned to PHP, a powerful WEB development language, and led the development of Online education websites.
Around 2011, as Java becomes more and more powerful in the web development space.</description>
    </item>
    
    <item>
      <title>Filebeat and Logstash config</title>
      <link>https://blog.wisekee.com/post/logstash_configure/</link>
      <pubDate>Fri, 10 Aug 2018 00:00:00 +0000</pubDate>
      
      <guid>https://blog.wisekee.com/post/logstash_configure/</guid>
      <description>The logs collect workflow  Filebeat gather the file path log files then send to Logstash 5044 port The logstash receive and transform extract fields and send to Elasticsearch  The Filebeat config file is: /etc/filebeat.yml  installing the Filebeat script:  1#!/bin/bash 2FILEBEAT_NAME=filebeat-6.7.2-x86_64.rpm 3# install filebeat 4curl -L -O https://artifacts.elastic.co/downloads/beats/filebeat/${FILEBEAT_NAME} 5sudo rpm -vi ${FILEBEAT_NAME} &amp;amp;&amp;amp; sudo rm ${FILEBEAT_NAME} 6sudo chkconfig --add filebeat 7sudo chkconfig filebeat on 8sudo mv -f filebeat.</description>
    </item>
    
    <item>
      <title>Configuration and Installing NFS on ubuntu</title>
      <link>https://blog.wisekee.com/post/ubuntu-install-nfs/</link>
      <pubDate>Fri, 02 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>https://blog.wisekee.com/post/ubuntu-install-nfs/</guid>
      <description>1#updating the system and install nfs daemon 2sudo apt-get update 3sudo apt install nfs-kernel-server 4 5#view the relative info about NFS 6sudo cat /proc/fs/nfsd/versions 7cat /etc/default/nfs-kernel-server 8cat /etc/default/nfs-common 9 10#create and bind the NFS directory in host hard disk 11sudo mkdir -p /srv/nfs4/data1 12sudo mkdir -p /srv/nfs4/data2 13sudo mount --bind /data2/nfs /srv/nfs4/data1 14sudo mount --bind /data3/nfs /srv/nfs4/data2 15 16#let binds permanent effect 17sudo vi /etc/fstab 18/data1/nfs /srv/nfs4/data2 none bind 0 0 19/data2/nfs /srv/nfs4/data3 none bind 0 0 20 21sudo vi /etc/exports 22# add following content to the file 23/srv/nfs4 192.</description>
    </item>
    
    <item>
      <title>Hugo usage issues summary</title>
      <link>https://blog.wisekee.com/post/hugo-usage-issues/</link>
      <pubDate>Wed, 16 Aug 2017 00:00:00 +0000</pubDate>
      
      <guid>https://blog.wisekee.com/post/hugo-usage-issues/</guid>
      <description>Usage scene   In my github repo initialize two repos
 One to storage Hugo sourcecode and markdown files And other one use release finaly site resources    Has two folders themes and public as github submodes
1 git submodule add https://github.com/don.chen/blog.github.io public 2 git submodule update --init and every time wited markdown article and execute
1git submodule update public 2git pull origin master 3cd public &amp;amp;&amp;amp; git add .</description>
    </item>
    
  </channel>
</rss>